{
	"name": "EducationNutritionAnalysisByLocationDesc",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "SparkPool01",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "d745bd29-13d4-42cc-8dea-a3bc1c01b3fe"
			}
		},
		"metadata": {
			"saveOutput": true,
			"synapse_widget": {
				"version": "0.1",
				"state": {
					"acbdbca6-f032-4d44-aae6-e8ae3e666332": {
						"type": "Synapse.DataFrame",
						"sync_state": {
							"table": {
								"rows": [
									{
										"0": "Massachusetts",
										"1": "Fruit and Vegetable Consumption <1x Daily",
										"2": "27.016666666666666"
									},
									{
										"0": "New Hampshire",
										"1": "Fruit and Vegetable Consumption <1x Daily",
										"2": "26.529166666666665"
									},
									{
										"0": "Vermont",
										"1": "Fruit and Vegetable Consumption <1x Daily",
										"2": "24.53333333333333"
									},
									{
										"0": "Oregon",
										"1": "Fruit and Vegetable Consumption <1x Daily",
										"2": "27.7"
									},
									{
										"0": "Maine",
										"1": "Fruit and Vegetable Consumption <1x Daily",
										"2": "24.45"
									}
								],
								"schema": [
									{
										"key": "0",
										"name": "State",
										"type": "string"
									},
									{
										"key": "1",
										"name": "Grouped_Question",
										"type": "string"
									},
									{
										"key": "2",
										"name": "Average %",
										"type": "double"
									}
								],
								"truncated": false
							},
							"isSummary": false,
							"language": "scala",
							"wranglerEntryContext": {
								"candidateVariableNames": [
									"df_best_states"
								],
								"dataframeType": "pyspark"
							}
						},
						"persist_state": {
							"view": {
								"type": "details",
								"chartOptions": {
									"chartType": "column",
									"aggregationType": "avg",
									"categoryFieldKeys": [
										"0"
									],
									"seriesFieldKeys": [
										"2"
									],
									"isStacked": false
								}
							}
						}
					},
					"58d904d6-fd36-491c-afc9-966769d40311": {
						"type": "Synapse.DataFrame",
						"sync_state": {
							"table": {
								"rows": [
									{
										"0": "Virgin Islands",
										"1": "Fruit and Vegetable Consumption <1x Daily",
										"2": "35.7125"
									},
									{
										"0": "Puerto Rico",
										"1": "Fruit and Vegetable Consumption <1x Daily",
										"2": "49.75"
									},
									{
										"0": "Mississippi",
										"1": "Fruit and Vegetable Consumption <1x Daily",
										"2": "35.375"
									},
									{
										"0": "Louisiana",
										"1": "Fruit and Vegetable Consumption <1x Daily",
										"2": "36.4"
									},
									{
										"0": "Guam",
										"1": "Fruit and Vegetable Consumption <1x Daily",
										"2": "36.13333333333333"
									}
								],
								"schema": [
									{
										"key": "0",
										"name": "State",
										"type": "string"
									},
									{
										"key": "1",
										"name": "Grouped_Question",
										"type": "string"
									},
									{
										"key": "2",
										"name": "Average %",
										"type": "double"
									}
								],
								"truncated": false
							},
							"isSummary": false,
							"language": "scala",
							"wranglerEntryContext": {
								"candidateVariableNames": [
									"df_worst_states"
								],
								"dataframeType": "pyspark"
							}
						},
						"persist_state": {
							"view": {
								"type": "details",
								"chartOptions": {
									"chartType": "column",
									"aggregationType": "avg",
									"categoryFieldKeys": [
										"0"
									],
									"seriesFieldKeys": [
										"2"
									],
									"isStacked": false,
									"binsNumber": 10
								}
							}
						}
					}
				}
			},
			"enableDebugMode": false,
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/33b0df95-be77-4791-89e3-a10226e5b46d/resourceGroups/bigdata-rg/providers/Microsoft.Synapse/workspaces/bigsynapsews01/bigDataPools/SparkPool01",
				"name": "SparkPool01",
				"type": "Spark",
				"endpoint": "https://bigsynapsews01.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPool01",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net",
					"authHeader": null
				},
				"sparkVersion": "3.4",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"extraHeader": null
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"collapsed": false
				},
				"source": [
					"# Step 1: Load CSV from Azure Data Lake\n",
					"file_path = 'abfss://bigdata-project@nutritionedudatalake.dfs.core.windows.net/raw/nutrition_data/Nutrition__Physical_Activity__and_Obesity_-_Behavioral_Risk_Factor_Surveillance_System.csv'\n",
					"\n",
					"import pandas as pd\n",
					"import pyspark\n",
					"from pyspark.sql import SparkSession\n",
					"\n",
					"# Start a Spark session\n",
					"spark = SparkSession.builder.appName('NutritionAnalysis').getOrCreate()\n",
					"\n",
					"# Load CSV into DataFrame\n",
					"df = pd.read_csv(file_path)\n",
					"\n",
					"# Step 2: Filter for fruit & vegetable habits and education levels\n",
					"nutrition_df = df[df['Class'] == 'Fruits and Vegetables']\n",
					"\n",
					"# Filter rows where StratificationCategory1 is 'Education'\n",
					"education_nutrition_df = nutrition_df[nutrition_df['StratificationCategory1'] == 'Education'].copy()\n",
					"\n",
					"# Step 3: Create a unified 'Grouped_Question' column for fruit and vegetable questions\n",
					"education_nutrition_df['Grouped_Question'] = 'Fruit and Vegetable Consumption <1x Daily'\n",
					"\n",
					"# Step 4: Group the data by State, Grouped_Question, and Education Level\n",
					"summary = (\n",
					"    education_nutrition_df\n",
					"    .groupby(['Grouped_Question', 'Stratification1', 'LocationDesc'])['Data_Value']\n",
					"    .mean()\n",
					"    .reset_index()\n",
					"    .rename(columns={\n",
					"        'Stratification1': 'Education Level',\n",
					"        'LocationDesc': 'State',\n",
					"        'Data_Value': 'Average %'\n",
					"    })\n",
					")\n",
					"\n",
					"# Step 5: Get the top 5 healthiest states (lowest percentage for fruit and vegetable consumption)\n",
					"best_states = summary.groupby(['State', 'Grouped_Question'])['Average %'].mean().reset_index()\n",
					"best_states_sorted = best_states.sort_values(by='Average %', ascending=True)\n",
					"\n",
					"# Get the top 5 healthiest states for the unified question\n",
					"top_5_states = best_states_sorted.groupby('Grouped_Question').head(5)\n",
					"\n",
					"# Step 6: Get the bottom 5 worst states (highest percentage for fruit and vegetable consumption)\n",
					"worst_states = summary.groupby(['State', 'Grouped_Question'])['Average %'].mean().reset_index()\n",
					"worst_states_sorted = worst_states.sort_values(by='Average %', ascending=False)\n",
					"\n",
					"# Get the bottom 5 worst states for the unified question\n",
					"bottom_5_states = worst_states_sorted.groupby('Grouped_Question').head(5)\n",
					"\n",
					"# Step 7: Save best 5 states to Azure Data Lake as Parquet\n",
					"best_states_df = spark.createDataFrame(top_5_states)\n",
					"\n",
					"best_states_df.write.mode(\"overwrite\").parquet(\n",
					"    \"abfss://bigdata-project@nutritionedudatalake.dfs.core.windows.net/processed/Top_5_Healthiest_States_Fruit_Veg_Consumption.parquet\"\n",
					")\n",
					"\n",
					"# Step 8: Save worst 5 states to Azure Data Lake as Parquet\n",
					"worst_states_df = spark.createDataFrame(bottom_5_states)\n",
					"\n",
					"worst_states_df.write.mode(\"overwrite\").parquet(\n",
					"    \"abfss://bigdata-project@nutritionedudatalake.dfs.core.windows.net/processed/Bottom_5_Worst_States_Fruit_Veg_Consumption.parquet\"\n",
					")\n",
					"\n",
					"# Step 9: Load the Parquet files again to register as Spark Tables\n",
					"df_best_states = spark.read.parquet(\"abfss://bigdata-project@nutritionedudatalake.dfs.core.windows.net/processed/Top_5_Healthiest_States_Fruit_Veg_Consumption.parquet\")\n",
					"df_worst_states = spark.read.parquet(\"abfss://bigdata-project@nutritionedudatalake.dfs.core.windows.net/processed/Bottom_5_Worst_States_Fruit_Veg_Consumption.parquet\")\n",
					"\n",
					"# Display the best and worst states dataframes\n",
					"display(df_best_states)\n",
					"display(df_worst_states)\n",
					"\n",
					"# Step 10: Register both datasets as Spark tables to appear in Synapse Studio > Data\n",
					"df_best_states.write.mode(\"overwrite\").saveAsTable(\"Top_5_Healthiest_States_Fruit_Veg_Consumption\")\n",
					"df_worst_states.write.mode(\"overwrite\").saveAsTable(\"Bottom_5_Worst_States_Fruit_Veg_Consumption\")\n",
					"\n",
					""
				],
				"execution_count": 14
			}
		]
	}
}